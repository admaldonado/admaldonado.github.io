---
layout: external
title: Learning Latent Variable Models from Non-Stationary Data Streams
role: Mathematics, 2020
category: papers
external_url:
tags: [sade, rnb, smooth]
image:
  thumb: hppjournal.png
published: true
---

**First Author**. Joint work with Ramos-Lo패pez D., Nielsen, T. D., Langseth, H., Salmero패n, A.

<!--

 Making inferences based on a data stream is challenging for several reasons.
First of all, it requires continuous model updating and the ability to handle a posterior distribution
conditioned on an unbounded data set. Secondly, the underlying data distribution may drift from
one time step to another, and the classic i.i.d. (or data exchangeability) assumption does not hold
any more. In this paper, we present a Bayesian approach which addresses these issues for general
latent variable models within the conjugate exponential family. Our proposal makes use of a novel
scheme based on hierarchical (non-conjugate) priors to explicitly model temporal changes of the
model parameters, which induces an exponential forgetting mechanism with adaptive forgetting
rates. A variational inference scheme is derived which maintains the computational efficiency of
variational methods over conjugate models.


Masegosa, A. R., Ramos-Lo패pez D., Nielsen, T. D., Langseth, H., Salmero패n, A. Learning Latent Variable Models from Non-Stationary Data Streams. Submitted to Bayesian Analysis 2019.

-->
<a href="https://www.mdpi.com/2227-7390/8/11/1942"><i class="fa fa-file-pdf-o" aria-hidden="true"> PDF</i></a> 
<a href="https://github.com/amidst/toolbox"><i class="fa fa-github" aria-hidden="true" > Github</i></a>

